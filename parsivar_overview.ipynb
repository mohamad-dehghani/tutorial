{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"B Titr\" size=5>\n",
    "\t\t<div align=center>\n",
    "\t\t\t<font size=30>\n",
    "                <p></p>\n",
    "\t\t\t\t<p></p>\n",
    "مروری بر ابزار Parsivar\n",
    "\t\t\t\t<p></p>\n",
    "\t\t\t</font>\n",
    "\t\t\t<font color=blue>\n",
    "اسفند 1400\n",
    "            </font>\n",
    "\t\t\t<br />\n",
    "            <br />\n",
    "\t\t</div>\n",
    "\t\t<hr />\n",
    "\t\t<style type=\"text/css\" scoped>\n",
    "        p{\n",
    "        border: 1px solid #a2a9b1;background-color: #f8f9fa;display: inline-block;\n",
    "        };\n",
    "        </style>\n",
    "\t\t<div>\n",
    "\t\t\t<h3>فهرست مطالب</h3>\n",
    "\t\t\t<ul style=\"margin-right: 0;\">\n",
    "\t\t\t\t<li>\n",
    "                    <a href=\"#sec_import\">\n",
    "                        واردکردن و بارگزاری داده\n",
    "                    </a>\n",
    "                </li>\n",
    "                <li>\n",
    "                    <a href=\"#sec_data_helper\">\n",
    "                        DataHelper\n",
    "                    </a>\n",
    "                </li>\n",
    "                <li>\n",
    "                    <a href=\"#sec_classifier_chunk_parser\">\n",
    "                        ClassifierChunkParser\n",
    "                    </a>\n",
    "                </li>\n",
    "                <li>\n",
    "                    <a href=\"#sec_normalizer\">\n",
    "                        یکسان‌ساز(Normalizer)\n",
    "                    </a>\n",
    "                </li>\n",
    "                <li>\n",
    "                    <a href=\"#sec_tokenizer\">\n",
    "                        واحدساز(Tokenizer)\n",
    "                    </a> \n",
    "                </li>\n",
    "                <li>\n",
    "                    <a href=\"#sec_stemmer\">\n",
    "                        ریشه‌یاب(Stemmer)\n",
    "                    </a> \n",
    "                </li>\n",
    "                <li>\n",
    "                    <a href=\"#sec_pos_tagger\">\n",
    "                        برچسب‌زننده‌ی نقش کلمات(POS Tagger)\n",
    "                    </a> \n",
    "                </li>\n",
    "                <li>\n",
    "                    <a href=\"#sec_chunker\">\n",
    "                        بخش‌ساز(Chunker)\n",
    "                    </a> \n",
    "                </li>\n",
    "                <li>\n",
    "\t\t\t\t\t<a href=\"#sec_dependency_parser\">\n",
    "                        تجزیه‌گر وابستگی(Dependency Parser)\n",
    "                    </a>\n",
    "\t\t\t\t</li>\n",
    "                <li>\n",
    "\t\t\t\t\t<a href=\"#sec_spell_check\">\n",
    "                        بررسی املا(Spell Check)\n",
    "                    </a>\n",
    "\t\t\t\t</li>\n",
    "                <li>\n",
    "\t\t\t\t\t<a href=\"#sec_resources\">\n",
    "                        منابع\n",
    "                    </a>\n",
    "\t\t\t\t</li>\n",
    "\t\t\t</ul>\n",
    "\t\t</div>\n",
    "\t</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p></p>\n",
    "<br />\n",
    "<div id=\"sec_import\" style=\"direction:rtl;line-height:300%;\">\n",
    " <font face=\"B Titr\" size=5>\n",
    "  <font color=black size=6>\n",
    "  واردکردن و بارگزاری اولیه      \n",
    "  </font>\n",
    "  <p></p>\n",
    "  <hr>\n",
    " </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A7MHoYiTEaXR",
    "outputId": "49764495-0d46-4f6f-c765-280c96308c43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.10\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fg71jwd1ggP_",
    "outputId": "b4bb116a-9d5f-4c28-db0c-b701f5e5f496"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: libwapiti in /home/mohsen-mahmoudzadeh/.local/lib/python3.8/site-packages (0.2.1)\r\n",
      "Requirement already satisfied: parsivar in /home/mohsen-mahmoudzadeh/.local/lib/python3.8/site-packages (0.2.3)\r\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from libwapiti) (1.14.0)\r\n",
      "Requirement already satisfied: nltk==3.4.5 in /home/mohsen-mahmoudzadeh/.local/lib/python3.8/site-packages (from parsivar) (3.4.5)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install libwapiti parsivar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wu_yMXSBggQB",
    "outputId": "694f25e4-7f28-45b0-8fae-abcbb3968f7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: libwapiti\n",
      "Version: 0.2.1\n",
      "Summary: Python bindings for libwapiti\n",
      "Home-page: UNKNOWN\n",
      "Author: Adam Svanberg\n",
      "Author-email: asvanberg@gmail.com\n",
      "License: UNKNOWN\n",
      "Location: /home/mohsen-mahmoudzadeh/.local/lib/python3.8/site-packages\n",
      "Requires: six\n",
      "Required-by: hazm\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show libwapiti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parsivar import *\n",
    "import pprint\n",
    "pprinter = pprint.PrettyPrinter(indent=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p></p>\n",
    "<br />\n",
    "<div id=\"sec_data_helper\" style=\"direction:rtl;line-height:300%;\">\n",
    " <font face=\"B Nazanin\" size=6>\n",
    "  <font face=\"B Titr\" color=black size=5>\n",
    "DataHelper\n",
    "        </font>\n",
    "  <p></p>\n",
    "  <hr>\n",
    "     کلاس DataHelper شامل چندین متد پرکاربرد برای بارگزاری یا ذخیره فایل‌ها و پیش‌پردازش‌های اولیه و ساده است که عمدتا در کلاس‌ها و ماژول‌های دیگر مورد استفاده قرار می‌گیرند.\n",
    "<br/>\n",
    "     \n",
    "        \n",
    " </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p></p>\n",
    "<br />\n",
    "<div id=\"sec_classifier_chunk_parser\" style=\"direction:rtl;line-height:300%;\">\n",
    " <font face=\"B Nazanin\" size=6>\n",
    "  <font face=\"B Titr\" color=black size=5>\n",
    "ClassifierChunkParser\n",
    "        </font>\n",
    "  <p></p>\n",
    "  <hr>\n",
    "     کلاس ClassifierChunkParser که در فایل token_merger.py قرار دارد بیشتر در فاز مقداردهی اولیه Normalizer مورد استفاده قرار می‌گیرد. \n",
    "<br/>\n",
    "     \n",
    "        \n",
    " </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "به گزارش خبرنگار حوزه بهداشت و درمان گروه علمی پزشکی باشگاه خبرنگاران جوان؛ محمد آقاجانی روز دوشنبه در نشست مشترک و هم اندیشی اعضای کمیسیون برنامه، بودجه و محاسبات مجلس و شورای معاونین وزارت بهداشت، اظهار داشت: در بیش از ۶۰۰ کلینیک ویژه در سطح کشور از ابتدای طرح تحول سلامت تا پایان سال گذشته، ۱۱۰ میلیون بار ویزیت تخصصی و فوق تخصصی با دریافت بهای بسیار اندک حدود ۳ هزار تومانی برای مردم طبقات محروم و متوسط انجام شد. وی به بیان مهمترین مشکلات پیش روی طرح تحول سلامت پرداخت و گفت: مهمترین معضل این طرح، عدم پایداری منابع است و اعتبارات وزارت بهداشت در سه سال اخیر به طور کامل محقق نشد. آقاجانی تصریح کرد: در سال ۹۵ معادل یک سوم بودجه سال ۹۳، به وزارت بهداشت بودجه تخصیص یافت اما خدمات حوزه سلامت همچنان با تلاش‌ها و زحمات جامعه پزشکی، پرستاری و کادر بهداشتی و درمانی کشور، بدون هیچ گونه کاستی به مردم ارائه می‌شود. معاون درمان وزارت بهداشت تاکید کرد: برای جبران کاهش بودجه وزارت بهداشت در سال سوم اجرای طرح تحول سلامت نسبت به سال اول، در هزینه‌های به طور جدی صرفه جویی کردیم. اما سال گذشته از محل هدفمندی یارانه‌ها نیز اعتباری دریافت نکردیم. آقاجانی در خصوص وضعیت مطالبات وزارت بهداشت از بیمه‌ها، یادآور شد: بیمارستانهای وزارت بهداشت هنوز مطالبات ۷ ماه از سال گذشته را از بیمه‌ها دریافت نکرده‌اند و حدود ۹ هزار و ۵۰۰ میلیارد تومان اسناد ارسالی به بیمه‌ها دارند. وی به وجود سامانه مرکزی خدمات بستری در وزارت بهداشت اشاره کرد و افزود: بر اساس اطلاعات این سامانه، رشد خدمات بستری پس از طرح تحول سلامت، فقط ۵ درصد است در حالی که شاهد رشد ۱۱ درصدی بیمه شدگان بودیم بنابراین تقاضای القایی ایجاد نشده اما در حوزه خدمات سرپایی ممکن است تقاضای القای وجود داشته باشد چون دفترچه سفیدی را در اختیار مردم قرار می‌دهیم که ممکن است هر روز به پرشکان مختلف مراجعه کنند و چندین خدمت پزشکی را دریافت کنند.\n"
     ]
    }
   ],
   "source": [
    "input_text = \"\"\"به گزارش خبرنگار حوزه بهداشت و درمان گروه علمی پزشکی باشگاه خبرنگاران جوان؛ محمد آقاجانی روز دوشنبه در نشست مشترک و هم اندیشی اعضای کمیسیون برنامه، بودجه و محاسبات مجلس و شورای معاونین وزارت بهداشت، اظهار داشت: در بیش از ۶۰۰ کلینیک ویژه در سطح کشور از ابتدای طرح تحول سلامت تا پایان سال گذشته، ۱۱۰ میلیون بار ویزیت تخصصی و فوق تخصصی با دریافت بهای بسیار اندک حدود ۳ هزار تومانی برای مردم طبقات محروم و متوسط انجام شد. وی به بیان مهمترین مشکلات پیش روی طرح تحول سلامت پرداخت و گفت: مهمترین معضل این طرح، عدم پایداری منابع است و اعتبارات وزارت بهداشت در سه سال اخیر به طور کامل محقق نشد. آقاجانی تصریح کرد: در سال ۹۵ معادل یک سوم بودجه سال ۹۳، به وزارت بهداشت بودجه تخصیص یافت اما خدمات حوزه سلامت همچنان با تلاش\\u200cها و زحمات جامعه پزشکی، پرستاری و کادر بهداشتی و درمانی کشور، بدون هیچ گونه کاستی به مردم ارائه می\\u200cشود. معاون درمان وزارت بهداشت تاکید کرد: برای جبران کاهش بودجه وزارت بهداشت در سال سوم اجرای طرح تحول سلامت نسبت به سال اول، در هزینه\\u200cهای به طور جدی صرفه جویی کردیم. اما سال گذشته از محل هدفمندی یارانه\\u200cها نیز اعتباری دریافت نکردیم. آقاجانی در خصوص وضعیت مطالبات وزارت بهداشت از بیمه\\u200cها، یادآور شد: بیمارستانهای وزارت بهداشت هنوز مطالبات ۷ ماه از سال گذشته را از بیمه\\u200cها دریافت نکرده\\u200cاند و حدود ۹ هزار و ۵۰۰ میلیارد تومان اسناد ارسالی به بیمه\\u200cها دارند. وی به وجود سامانه مرکزی خدمات بستری در وزارت بهداشت اشاره کرد و افزود: بر اساس اطلاعات این سامانه، رشد خدمات بستری پس از طرح تحول سلامت، فقط ۵ درصد است در حالی که شاهد رشد ۱۱ درصدی بیمه شدگان بودیم بنابراین تقاضای القایی ایجاد نشده اما در حوزه خدمات سرپایی ممکن است تقاضای القای وجود داشته باشد چون دفترچه سفیدی را در اختیار مردم قرار می\\u200cدهیم که ممکن است هر روز به پرشکان مختلف مراجعه کنند و چندین خدمت پزشکی را دریافت کنند.\"\"\"\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p></p>\n",
    "<br />\n",
    "<div id=\"sec_normalizer\" style=\"direction:rtl;line-height:300%;\">\n",
    " <font face=\"B Nazanin\" size=6>\n",
    "  <font face=\"B Titr\" color=black size=5>\n",
    "یکسان‌ساز(Normalizer)\n",
    "        </font>\n",
    "  <p></p>\n",
    "  <hr>\n",
    "هدف اصلی در بخش یکسان‌ساز، یکپارچه‌سازی و متحدالشکل‌کردن کاراکترها به منظور کنترل بیشتر بر نتایج پردازش‌های پیشرفته‌تر بر متن است.\n",
    "        <br>\n",
    "        فرایند یکسان‌سازی متن در ابزار Parsivar به کمک متد normalize کلاس Normalizer انجام می‌شود؛ متدی که در داخل خود متدهای زیر را فراخوانی کرده و فرایند یکسان‌سازی متن را انجام می‌دهد:\n",
    "<br/>\n",
    "     \n",
    "        \n",
    " </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"B Nazanin\" size=6>\n",
    "\t\t<div>\n",
    "\t\t\t<ul style=\"margin-right: 0;\">\n",
    "\t\t\t\t<li>\n",
    "                     space_correction\n",
    "                    <ul style=\"margin-right: 0;\">\n",
    "                        <li>\n",
    "                        space_correction_plus1\n",
    "                            <ul style=\"margin-right: 0;\">\n",
    "                                <li>\n",
    "                                 حذف فاصله‌های اضافی بر اساس دیکشنری 1 \n",
    "                                </li>\n",
    "                            </ul>\n",
    "                        </li>\n",
    "                        <li>\n",
    "                             space_correction_plus2\n",
    "                            <ul style=\"margin-right: 0;\">\n",
    "                                <li>\n",
    "                                    حذف فاصله‌های اضافی بر اساس دیکشنری 2 \n",
    "                                </li>\n",
    "                            </ul>\n",
    "                        </li>\n",
    "                        <li>\n",
    "                             space_correction_plus3\n",
    "                            <ul style=\"margin-right: 0;\">\n",
    "                                <li>\n",
    "                                 حذف فاصله‌های اضافی بر اساس دیکشنری 3 \n",
    "                                </li>\n",
    "                            </ul>\n",
    "                        </li>\n",
    "                    </ul>\n",
    "                    <li>\n",
    "                        sub_alphabets\n",
    "                    </li>\n",
    "                    <ul style=\"margin-right: 0;\">\n",
    "                        <li>\n",
    "                            نگاشت الفبا به حالات استاندارد و نرمال\n",
    "                        </li>\n",
    "                    </ul>\n",
    "                    <li>\n",
    "                        load_dictionary\n",
    "                    </li>\n",
    "                    <ul style=\"margin-right: 0;\">\n",
    "                        <li>\n",
    "                            بارگزاری دیکشنری‌های مربوط به یکسان‌ساز\n",
    "                        </li>\n",
    "                    </ul>\n",
    "                </li>\n",
    "\t\t\t</ul>\n",
    "\t\t</div>\n",
    "\t</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "QIqmKYv9EaXW"
   },
   "outputs": [],
   "source": [
    "normalizer = Normalizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7y22zWoTEaXX",
    "outputId": "2f025cdb-ddfe-499e-ed8a-9943df98fbc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "به گزارش خبرنگار حوزه بهداشت و درمان گروه علمی پزشکی باشگاه خبرنگاران جوان ؛ محمد آقاجانی روز دوشنبه در نشست مشترک و هم اندیشی اعضای کمیسیون برنامه ، بودجه و محاسبات مجلس و شورای معاونین وزارت بهداشت ، اظهار داشت : در بیش از 600 کلینیک ویژه در سطح کشور از ابتدای طرح تحول سلامت تا پایان سال گذشته ، 110 میلیون بار ویزیت تخصصی و فوق تخصصی با دریافت بهای بسیار اندک حدود 3 هزار تومانی برای مردم طبقات محروم و متوسط انجام شد . وی به بیان مهمترین مشکلات پیش روی طرح تحول سلامت پرداخت و گفت : مهمترین معضل این طرح ، عدم پایداری منابع است و اعتبارات وزارت بهداشت در سه سال اخیر به‌طور کامل محقق نشد . آقاجانی تصریح کرد : در سال 95 معادل یک سوم بودجه سال 93 ، به وزارت بهداشت بودجه تخصیص یافت اما خدمات حوزه سلامت همچنان با تلاش‌ها و زحمات جامعه پزشکی ، پرستاری و کادر بهداشتی و درمانی کشور ، بدون هیچ‌گونه کاستی به مردم ارائه می‌شود . معاون درمان وزارت بهداشت تاکید کرد : برای جبران کاهش بودجه وزارت بهداشت در سال سوم اجرای طرح تحول سلامت نسبت به سال اول ، در هزینه‌های به‌طور جدی صرفه‌جویی کردیم . اما سال گذشته از محل هدفمندی یارانه‌ها نیز اعتباری دریافت نکردیم . آقاجانی در خصوص وضعیت مطالبات وزارت بهداشت از بیمه‌ها ، یادآور شد : بیمارستانهای وزارت بهداشت هنوز مطالبات 7 ماه از سال گذشته را از بیمه‌ها دریافت نکرده‌اند و حدود 9 هزار و 500 میلیارد تومان اسناد ارسالی به بیمه‌ها دارند . وی به وجود سامانه مرکزی خدمات بستری در وزارت بهداشت اشاره کرد و افزود : بر اساس اطلاعات این سامانه ، رشد خدمات بستری پس از طرح تحول سلامت ، فقط 5 درصد است در حالی که شاهد رشد 11 درصدی بیمه شدگان‌بودیم بنابراین تقاضای القایی ایجاد‌نشده‌اما در حوزه خدمات سرپایی ممکن است تقاضای القای وجود داشته باشد چون دفترچه سفیدی را در اختیار مردم قرار می‌دهیم که ممکن است هر روز به پرشکان مختلف مراجعه کنند و چندین خدمت پزشکی را دریافت کنند .\n"
     ]
    }
   ],
   "source": [
    "print(normalizer.normalize(input_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p></p>\n",
    "<br />\n",
    "<div id=\"sec_informal_normalizer\" style=\"direction:rtl;line-height:300%;\">\n",
    " <font face=\"B Nazanin\" size=6>\n",
    "  <font face=\"B Titr\" color=black size=5>\n",
    "یکسان‌ساز تاریخ(Date Normalizer)\n",
    "        </font>\n",
    "  <p></p>\n",
    "  <hr>\n",
    "با توجه به تنوع نوشتاری تاریخ‌ها در متن فارسی، کلاس DateNormalizer به منظور یکسان‌سازی تنوع نوشتاری تاریخ‌ها توسعه داده شده است.\n",
    "        <br>\n",
    "     در این کلاس متد normalize_dates به منظور یکسان‌سازی استفاده می‌شود. به کمک متد find_date_part بخش‌های مربوط به تاریخ(یا حداقل بخش‌هایی که کاندیدی برای تاریخ بودن هستند) یافته می‌شوند. متد find_number_location و normalize_numbers به منظور یافتن موقعیت اعداد و یکسان‌سازی آنها و متدهای کمکی convert2num، list2num و is_number نیز برای تبدیل نوع داده‌ها مورد استفاده قرار می‌گیرند.\n",
    "\n",
    " </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "miFrBc3yEaXY"
   },
   "outputs": [],
   "source": [
    "date_normalizer = Normalizer(date_normalizing_needed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pfvTEt7yEaXa",
    "outputId": "b3fc4c1d-a093-4c18-8479-809345b93c6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With date_normazliering_needed parameter:  y1166m3d9 \n",
      "Without date_normazliering_needed parameter: 9 / 3 / 1166\n"
     ]
    }
   ],
   "source": [
    "date_string = '۹/۳/۱۱۶۶'\n",
    "normalized_date = date_normalizer.normalize(date_string)\n",
    "no_normalized_date = normalizer.normalize(date_string)\n",
    "print('With date_normazliering_needed parameter: ' + normalized_date)\n",
    "print('Without date_normazliering_needed parameter: ' + no_normalized_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p></p>\n",
    "<br />\n",
    "<div id=\"sec_informal_normalizer\" style=\"direction:rtl;line-height:300%;\">\n",
    " <font face=\"B Nazanin\" size=6>\n",
    "  <font face=\"B Titr\" color=black size=5>\n",
    "یکسان‌ساز فینگلیش(Pinglish Normalizer)\n",
    "        </font>\n",
    "  <p></p>\n",
    "  <hr>\n",
    "با توجه به این که بخش قابل ملاحظه‌ای از متون موجود در فضای شبکه‌های اجتماعی و پیام‌رسان‌ها به صورت فینگلیش نوشته می‌شوند در ابزارParsivar کلاس PinglishNormalizer برای تبدیل از فینگلیش به فارسی در نظر گرفته شده است.\n",
    "        <br>\n",
    "     در این کلاس متد pingilish2persian به منظور تبدیل متن فینگلیش به فارسی مورد استفاده قرار می گیرد. ابتدا بررسی می‌شود که توکن فعلی در دیکشنری کلمات انگلیسی موجود است و در صورت عدم وجود، معادل فارسی آن را می‌سازد. این معادل‌سازی به کمک تفسیر گروه کاراکترها(صامت‌ها، مصوت‌ها، حروف متوالیا تکراری، نگاشت از گروه کاراکترهای فینگلیش به کاراکتر یا گروه کاراکترهای فارسی ) انجام می‌شود.\n",
    "\n",
    " </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "V8PhVBk3EaXa"
   },
   "outputs": [],
   "source": [
    "pinglish_normalizer = Normalizer(pinglish_conversion_needed = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ysmg0M3xEaXc",
    "outputId": "9bba3062-1096-40a0-d329-d404bed00e4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without pinglish_conversion_needed parameter: bime mashin ro az ki begiram az ki\n",
      "With pinglish_conversion_needed parameter: بیمه ماشین رو از کی بگیرم از کی\n"
     ]
    }
   ],
   "source": [
    "pinglish_string = 'bime mashin ro az ki begiram az ki'\n",
    "pingilsh_converted = pinglish_normalizer.normalize(pinglish_string)\n",
    "no_pingilsh_converted = normalizer.normalize(pinglish_string)\n",
    "print('Without pinglish_conversion_needed parameter: ' + no_pingilsh_converted)\n",
    "print('With pinglish_conversion_needed parameter: ' + pingilsh_converted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p></p>\n",
    "<br />\n",
    "<div id=\"sec_tokenizer\" style=\"direction:rtl;line-height:300%;\">\n",
    " <font face=\"B Nazanin\" size=6>\n",
    "  <font face=\"B Titr\" color=black size=5>\n",
    "            واحدساز(Tokenizer)\n",
    "  </font>\n",
    "  <p></p>\n",
    "  <hr>\n",
    "     برای بسیاری از پردازش‌ها نیاز به این وجود دارد که متن بر اساس کلمات یا جملات شکسته(tokenize) شود. کلاس Tokenizer این نیازمندی را برطرف می‌کند. متدهای tokenize_words و tokenize_sentences به ترتیب برای واحدسازی کلمات و جملات به کار می‌روند. کلمات بر مبنای فاصله از هم جدا شده و نیم فاصله‌ها حذف می‌شوند. در جملات نیز بر مبنای علامت سوال، علامت تعجب، نقطه، دونقطه و نقطه ویرگول، حذف کاراکترهای اضافی و فاصله‌گذاری‌های لازم(در متد add_tab) انجام می‌شود و در نهایت بر اساس کاراکتر «t\\t\\» جملات واحدسازی می‌شوند.\n",
    "        <br>\n",
    " </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "bJDneVrpEaXe"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "Jffp-CvNEaXf"
   },
   "outputs": [],
   "source": [
    "tokenized_sents = tokenizer.tokenize_sentences(normalizer.normalize(input_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PZXImMu3EaXg",
    "outputId": "edee53a0-51a6-484e-ec34-21c26b41a856"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  'به گزارش خبرنگار حوزه بهداشت و درمان گروه علمی پزشکی باشگاه خبرنگاران جوان '\n",
      "   '؛ محمد آقاجانی روز دوشنبه در نشست مشترک و هم اندیشی اعضای کمیسیون برنامه ، '\n",
      "   'بودجه و محاسبات مجلس و شورای معاونین وزارت بهداشت ، اظهار داشت : در بیش از '\n",
      "   '600 کلینیک ویژه در سطح کشور از ابتدای طرح تحول سلامت تا پایان سال گذشته ، '\n",
      "   '110 میلیون بار ویزیت تخصصی و فوق تخصصی با دریافت بهای بسیار اندک حدود 3 '\n",
      "   'هزار تومانی برای مردم طبقات محروم و متوسط انجام شد  .',\n",
      "   ' وی به بیان مهمترین مشکلات پیش روی طرح تحول سلامت پرداخت و گفت : مهمترین '\n",
      "   'معضل این طرح ، عدم پایداری منابع است و اعتبارات وزارت بهداشت در سه سال '\n",
      "   'اخیر به\\u200cطور کامل محقق نشد  .',\n",
      "   ' آقاجانی تصریح کرد : در سال 95 معادل یک سوم بودجه سال 93 ، به وزارت بهداشت '\n",
      "   'بودجه تخصیص یافت اما خدمات حوزه سلامت همچنان با تلاش\\u200cها و زحمات جامعه '\n",
      "   'پزشکی ، پرستاری و کادر بهداشتی و درمانی کشور ، بدون هیچ\\u200cگونه کاستی به '\n",
      "   'مردم ارائه می\\u200cشود  .',\n",
      "   ' معاون درمان وزارت بهداشت تاکید کرد : برای جبران کاهش بودجه وزارت بهداشت '\n",
      "   'در سال سوم اجرای طرح تحول سلامت نسبت به سال اول ، در هزینه\\u200cهای '\n",
      "   'به\\u200cطور جدی صرفه\\u200cجویی کردیم  .',\n",
      "   ' اما سال گذشته از محل هدفمندی یارانه\\u200cها نیز اعتباری دریافت نکردیم  .',\n",
      "   ' آقاجانی در خصوص وضعیت مطالبات وزارت بهداشت از بیمه\\u200cها ، یادآور شد : '\n",
      "   'بیمارستانهای وزارت بهداشت هنوز مطالبات 7 ماه از سال گذشته را از '\n",
      "   'بیمه\\u200cها دریافت نکرده\\u200cاند و حدود 9 هزار و 500 میلیارد تومان اسناد '\n",
      "   'ارسالی به بیمه\\u200cها دارند  .',\n",
      "   ' وی به وجود سامانه مرکزی خدمات بستری در وزارت بهداشت اشاره کرد و افزود : '\n",
      "   'بر اساس اطلاعات این سامانه ، رشد خدمات بستری پس از طرح تحول سلامت ، فقط 5 '\n",
      "   'درصد است در حالی که شاهد رشد 11 درصدی بیمه شدگان\\u200cبودیم بنابراین '\n",
      "   'تقاضای القایی ایجاد\\u200cنشده\\u200cاما در حوزه خدمات سرپایی ممکن است '\n",
      "   'تقاضای القای وجود داشته باشد چون دفترچه سفیدی را در اختیار مردم قرار '\n",
      "   'می\\u200cدهیم که ممکن است هر روز به پرشکان مختلف مراجعه کنند و چندین خدمت '\n",
      "   'پزشکی را دریافت کنند  .']\n"
     ]
    }
   ],
   "source": [
    "pprinter.pprint(tokenized_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "wjw8MNb-EaXg"
   },
   "outputs": [],
   "source": [
    "tokenized_words = tokenizer.tokenize_words(normalizer.normalize(input_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IxyH2mnQEaXh",
    "outputId": "069cc436-b303-4649-bdc4-5beb5965128a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['به', 'گزارش', 'خبرنگار', 'حوزه', 'بهداشت', 'و', 'درمان', 'گروه', 'علمی', 'پزشکی', 'باشگاه', 'خبرنگاران', 'جوان', '؛', 'محمد', 'آقاجانی', 'روز', 'دوشنبه', 'در', 'نشست', 'مشترک', 'و', 'هم', 'اندیشی', 'اعضای', 'کمیسیون', 'برنامه', '،', 'بودجه', 'و', 'محاسبات', 'مجلس', 'و', 'شورای', 'معاونین', 'وزارت', 'بهداشت', '،', 'اظهار', 'داشت', ':', 'در', 'بیش', 'از', '600', 'کلینیک', 'ویژه', 'در', 'سطح', 'کشور', 'از', 'ابتدای', 'طرح', 'تحول', 'سلامت', 'تا', 'پایان', 'سال', 'گذشته', '،', '110', 'میلیون', 'بار', 'ویزیت', 'تخصصی', 'و', 'فوق', 'تخصصی', 'با', 'دریافت', 'بهای', 'بسیار', 'اندک', 'حدود', '3', 'هزار', 'تومانی', 'برای', 'مردم', 'طبقات', 'محروم', 'و', 'متوسط', 'انجام', 'شد', '.', 'وی', 'به', 'بیان', 'مهمترین', 'مشکلات', 'پیش', 'روی', 'طرح', 'تحول', 'سلامت', 'پرداخت', 'و', 'گفت', ':', 'مهمترین', 'معضل', 'این', 'طرح', '،', 'عدم', 'پایداری', 'منابع', 'است', 'و', 'اعتبارات', 'وزارت', 'بهداشت', 'در', 'سه', 'سال', 'اخیر', 'به\\u200cطور', 'کامل', 'محقق', 'نشد', '.', 'آقاجانی', 'تصریح', 'کرد', ':', 'در', 'سال', '95', 'معادل', 'یک', 'سوم', 'بودجه', 'سال', '93', '،', 'به', 'وزارت', 'بهداشت', 'بودجه', 'تخصیص', 'یافت', 'اما', 'خدمات', 'حوزه', 'سلامت', 'همچنان', 'با', 'تلاش\\u200cها', 'و', 'زحمات', 'جامعه', 'پزشکی', '،', 'پرستاری', 'و', 'کادر', 'بهداشتی', 'و', 'درمانی', 'کشور', '،', 'بدون', 'هیچ\\u200cگونه', 'کاستی', 'به', 'مردم', 'ارائه', 'می\\u200cشود', '.', 'معاون', 'درمان', 'وزارت', 'بهداشت', 'تاکید', 'کرد', ':', 'برای', 'جبران', 'کاهش', 'بودجه', 'وزارت', 'بهداشت', 'در', 'سال', 'سوم', 'اجرای', 'طرح', 'تحول', 'سلامت', 'نسبت', 'به', 'سال', 'اول', '،', 'در', 'هزینه\\u200cهای', 'به\\u200cطور', 'جدی', 'صرفه\\u200cجویی', 'کردیم', '.', 'اما', 'سال', 'گذشته', 'از', 'محل', 'هدفمندی', 'یارانه\\u200cها', 'نیز', 'اعتباری', 'دریافت', 'نکردیم', '.', 'آقاجانی', 'در', 'خصوص', 'وضعیت', 'مطالبات', 'وزارت', 'بهداشت', 'از', 'بیمه\\u200cها', '،', 'یادآور', 'شد', ':', 'بیمارستانهای', 'وزارت', 'بهداشت', 'هنوز', 'مطالبات', '7', 'ماه', 'از', 'سال', 'گذشته', 'را', 'از', 'بیمه\\u200cها', 'دریافت', 'نکرده\\u200cاند', 'و', 'حدود', '9', 'هزار', 'و', '500', 'میلیارد', 'تومان', 'اسناد', 'ارسالی', 'به', 'بیمه\\u200cها', 'دارند', '.', 'وی', 'به', 'وجود', 'سامانه', 'مرکزی', 'خدمات', 'بستری', 'در', 'وزارت', 'بهداشت', 'اشاره', 'کرد', 'و', 'افزود', ':', 'بر', 'اساس', 'اطلاعات', 'این', 'سامانه', '،', 'رشد', 'خدمات', 'بستری', 'پس', 'از', 'طرح', 'تحول', 'سلامت', '،', 'فقط', '5', 'درصد', 'است', 'در', 'حالی', 'که', 'شاهد', 'رشد', '11', 'درصدی', 'بیمه', 'شدگان\\u200cبودیم', 'بنابراین', 'تقاضای', 'القایی', 'ایجاد\\u200cنشده\\u200cاما', 'در', 'حوزه', 'خدمات', 'سرپایی', 'ممکن', 'است', 'تقاضای', 'القای', 'وجود', 'داشته', 'باشد', 'چون', 'دفترچه', 'سفیدی', 'را', 'در', 'اختیار', 'مردم', 'قرار', 'می\\u200cدهیم', 'که', 'ممکن', 'است', 'هر', 'روز', 'به', 'پرشکان', 'مختلف', 'مراجعه', 'کنند', 'و', 'چندین', 'خدمت', 'پزشکی', 'را', 'دریافت', 'کنند', '.']\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p></p>\n",
    "<br />\n",
    "<div id=\"sec_stemmer\" style=\"direction:rtl;line-height:300%;\">\n",
    " <font face=\"B Nazanin\" size=6>\n",
    "  <font face=\"B Titr\" color=black size=5>\n",
    "            ریشه‌یاب(Stemmer)\n",
    "  </font>\n",
    "  <p></p>\n",
    "  <hr>\n",
    "ریشه‌یابی عمدتا با هدف حذف وندهای متصل به اسم مورد استفاده قرار می‌گیرد.\n",
    "     <br/>\n",
    "     در ابزار Parsivar کلاس FindStems وظیفه ریشه‌یابی را بر عهده دارد. متد convert_to_stem این کلاس با حذف پیشوندها و پسوندها در زمان‌های مختلف(برای افعال) و یا تشخیص بی‌قاعده بودن آنها(برای اسم‌ها) ریشه کلمات را پیدا می‌کند.\n",
    "\n",
    " </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "16d7bPChEaXi"
   },
   "outputs": [],
   "source": [
    "stemmer = FindStems()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6EmsVnfBEaXi",
    "outputId": "2bc46fc3-d38b-44a6-d750-4cac59a07023"
   },
   "outputs": [],
   "source": [
    "stemmed_tokens = [stemmer.convert_to_stem(token) for token in tokenized_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['به', 'گزارش', 'خبرنگار', 'حوزه', 'بهداشت', 'و', 'درمان', 'گروه', 'علمی', 'پزشکی', 'باشگاه', 'خبرنگار', 'جوان', '؛', 'محمد', 'آقاجان', 'روز', 'دوشنبه', 'در', 'نشست', 'مشترک', 'و', 'هم', 'اندیشید&اندیش', 'عضو', 'کمیسیون', 'برنامه', '،', 'بودجه', 'و', 'محاسبات', 'مجلس', 'و', 'شورا', 'معاون', 'وزارت', 'بهداشت', '،', 'اظهار', 'داشت&دار', ':', 'در', 'بیش', 'از', '600', 'کلینیک', 'ویژه', 'در', 'سطح', 'کشور', 'از', 'ابتدا', 'طرح', 'تحول', 'سلامت', 'تا', 'پایان', 'سال', 'گذشته', '،', '110', 'میلیون', 'بار', 'ویزیت', 'تخصصی', 'و', 'فوق', 'تخصصی', 'با', 'دریافت', 'بهای', 'بسیار', 'اندک', 'حدود', '3', 'هزار', 'تومانی', 'برای', 'مردم', 'طبقات', 'محروم', 'و', 'متوسط', 'انجام', 'شد', '.', 'وی', 'به', 'بیان', 'مهم', 'مشکلات', 'پیش', 'روی', 'طرح', 'تحول', 'سلامت', 'پرداخت', 'و', 'گفت', ':', 'مهم', 'معضل', 'این', 'طرح', '،', 'عدم', 'پایداری', 'منبع', 'اس', 'و', 'اعتبارات', 'وزارت', 'بهداشت', 'در', 'سه', 'سال', 'اخیر', 'به\\u200cطور', 'کامل', 'محقق', 'شد&شو', '.', 'آقاجان', 'تصریح', 'کرد', ':', 'در', 'سال', '95', 'معادل', 'یک', 'سوم', 'بودجه', 'سال', '93', '،', 'به', 'وزارت', 'بهداشت', 'بودجه', 'تخصیص', 'یافت', 'اما', 'خدمات', 'حوزه', 'سلامت', 'همچنان', 'با', 'تلاش', 'و', 'زحمات', 'جامعه', 'پزشکی', '،', 'پرستاری', 'و', 'کادر', 'بهداشتی', 'و', 'درمانی', 'کشور', '،', 'بدون', 'هیچ\\u200cگونه', 'کاستی', 'به', 'مردم', 'ارائه', 'شد&شو', '.', 'معاون', 'درمان', 'وزارت', 'بهداشت', 'تاکید', 'کرد', ':', 'برای', 'جبران', 'کاهش', 'بودجه', 'وزارت', 'بهداشت', 'در', 'سال', 'سوم', 'اجرا', 'طرح', 'تحول', 'سلامت', 'نسبت', 'به', 'سال', 'اول', '،', 'در', 'هزینه', 'به\\u200cطور', 'جدی', 'صرفه\\u200cجویی', 'کرد&کن', '.', 'اما', 'سال', 'گذشته', 'از', 'محل', 'هدفمندی', 'یارانه', 'نیز', 'اعتباری', 'دریافت', 'کرد&کن', '.', 'آقاجان', 'در', 'خصوص', 'وضعیت', 'مطالبات', 'وزارت', 'بهداشت', 'از', 'بیمه', '،', 'یادآور', 'شد', ':', 'بیمارستان', 'وزارت', 'بهداشت', 'هنوز', 'مطالبات', '7', 'ماه', 'از', 'سال', 'گذشته', 'را', 'از', 'بیمه', 'دریافت', 'کرد&کن', 'و', 'حدود', '9', 'هزار', 'و', '500', 'میلیارد', 'تومان', 'اسناد', 'ارسالی', 'به', 'بیمه', 'داشت&دار', '.', 'وی', 'به', 'وجود', 'سامانه', 'مرکزی', 'خدمات', 'بستری', 'در', 'وزارت', 'بهداشت', 'اشاره', 'کرد', 'و', 'افزود&افزا', ':', 'بر', 'اساس', 'اطلاعات', 'این', 'سامانه', '،', 'رشد', 'خدمات', 'بستری', 'پس', 'از', 'طرح', 'تحول', 'سلامت', '،', 'فقط', '5', 'درصد', 'اس', 'در', 'حال', 'که', 'شاهد', 'رشد', '11', 'درصدی', 'بیمه', 'شدگان\\u200cبودیم', 'بنابراین', 'تقاضا', 'القایی', 'ایجاد\\u200cنشده\\u200cاما', 'در', 'حوزه', 'خدمات', 'سرپایی', 'ممکن', 'اس', 'تقاضا', 'القا', 'وجود', 'داشته', 'باشد', 'چون', 'دفترچه', 'سفیدی', 'را', 'در', 'اختیار', 'مردم', 'قرار', 'داد&ده', 'که', 'ممکن', 'اس', 'هر', 'روز', 'به', 'پرشکان', 'مختلف', 'مراجعه', 'کرد&کن', 'و', 'چندین', 'خدمت', 'پزشکی', 'را', 'دریافت', 'کرد&کن', '.']\n"
     ]
    }
   ],
   "source": [
    "print(stemmed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ewah3hP1EaXk",
    "outputId": "fb2708fe-0c1e-430b-cbe6-490c98779b34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "درختان >> درخت\n",
      "اژدها >> اژدها\n",
      "رفتارها >> رفتار\n",
      "برقص >> رقصید&رقص\n",
      "بنواز >> نواخت&نواز\n",
      "کفار >> کفار\n",
      "برآشفتن >> برآشفتن\n"
     ]
    }
   ],
   "source": [
    "word_tests = ['درختان' ,'اژدها' ,'رفتارها' ,'برقص' ,'بنواز' ,'کفار' ,'برآشفتن']\n",
    "for word in word_tests:\n",
    "    print(word, '>>', stemmer.convert_to_stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p></p>\n",
    "<br />\n",
    "<div id=\"sec_pos_tagger\" style=\"direction:rtl;line-height:300%;\">\n",
    " <font face=\"B Nazanin\" size=6>\n",
    "  <font face=\"B Titr\" color=black size=5>\n",
    "             برچسب‌گذار نقش کلمات(POS Tagger)\n",
    "  </font>\n",
    "  <p></p>\n",
    "  <hr>\n",
    "     برچسب‌گذاری نقش یا پاره‌های گفتار(Part-of-speech tagging)، فرایند برچسب‌گذاری یک واژه در یک متن است که آن برچسب، متناظر با نقش یا پاره‌گفتار(Part of speech) خاص آن واژه می‌باشد. برای مثال شناسایی واژه‌ها به عنوان «اسم»، «فعل»، «صفت»، «قید» و ... نوعی برچسب‌گذاری پاره‌های گفتار است.\n",
    "     <br/>\n",
    "در ابزار Parsivar، کلاس POStagger این برچسب‌گذاری را انجام می‌دهد. در سازنده این کلاس بر مبنای نوع سیستم‌عامل، مدل برچسب‌گذاری انتخاب می‌شود(در ویندوز، stanford و در غیر این صورت wapiti استفاده می‌شود). متد parse نیز بر اساس مدل برچسب‌گذاری، فرایند برچسب‌گذاری توسط مدل انجام می‌شود.\n",
    "     <br/>\n",
    "\n",
    " </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "HCVWfIKiEaXk"
   },
   "outputs": [],
   "source": [
    "tagger = POSTagger(tagging_model=\"wapiti\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xL1E3qygEaXl",
    "outputId": "8f5e04ad-60d8-4ee8-d704-80497b631dfb"
   },
   "outputs": [],
   "source": [
    "pos_tagged_example = tagger.parse(tokenized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "dbRabprrEaXl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  ('به', 'P'),\n",
      "   ('گزارش', 'N_SING'),\n",
      "   ('خبرنگار', 'N_SING'),\n",
      "   ('حوزه', 'N_SING'),\n",
      "   ('بهداشت', 'N_SING'),\n",
      "   ('و', 'CON'),\n",
      "   ('درمان', 'N_SING'),\n",
      "   ('گروه', 'N_SING'),\n",
      "   ('علمی', 'ADJ'),\n",
      "   ('پزشکی', 'N_SING'),\n",
      "   ('باشگاه', 'N_SING'),\n",
      "   ('خبرنگاران', 'N_PL'),\n",
      "   ('جوان', 'ADJ'),\n",
      "   ('؛', 'DELM'),\n",
      "   ('محمد', 'N_SING'),\n",
      "   ('آقاجانی', 'N_SING'),\n",
      "   ('روز', 'N_SING'),\n",
      "   ('دوشنبه', 'N_SING'),\n",
      "   ('در', 'P'),\n",
      "   ('نشست', 'N_SING'),\n",
      "   ('مشترک', 'ADJ'),\n",
      "   ('و', 'CON'),\n",
      "   ('هم', 'CON'),\n",
      "   ('اندیشی', 'N_SING'),\n",
      "   ('اعضای', 'N_PL'),\n",
      "   ('کمیسیون', 'N_SING'),\n",
      "   ('برنامه', 'N_SING'),\n",
      "   ('،', 'DELM'),\n",
      "   ('بودجه', 'N_SING'),\n",
      "   ('و', 'CON'),\n",
      "   ('محاسبات', 'N_PL'),\n",
      "   ('مجلس', 'N_SING'),\n",
      "   ('و', 'CON'),\n",
      "   ('شورای', 'N_SING'),\n",
      "   ('معاونین', 'N_PL'),\n",
      "   ('وزارت', 'N_SING'),\n",
      "   ('بهداشت', 'N_SING'),\n",
      "   ('،', 'DELM'),\n",
      "   ('اظهار', 'N_SING'),\n",
      "   ('داشت', 'V_PA'),\n",
      "   (':', 'DELM'),\n",
      "   ('در', 'P'),\n",
      "   ('بیش', 'ADJ'),\n",
      "   ('از', 'P'),\n",
      "   ('600', 'N_SING'),\n",
      "   ('کلینیک', 'N_SING'),\n",
      "   ('ویژه', 'ADJ'),\n",
      "   ('در', 'P'),\n",
      "   ('سطح', 'N_SING'),\n",
      "   ('کشور', 'N_SING'),\n",
      "   ('از', 'P'),\n",
      "   ('ابتدای', 'N_SING'),\n",
      "   ('طرح', 'N_SING'),\n",
      "   ('تحول', 'N_SING'),\n",
      "   ('سلامت', 'N_SING'),\n",
      "   ('تا', 'P'),\n",
      "   ('پایان', 'N_SING'),\n",
      "   ('سال', 'N_SING'),\n",
      "   ('گذشته', 'ADJ'),\n",
      "   ('،', 'DELM'),\n",
      "   ('110', 'NUM'),\n",
      "   ('میلیون', 'NUM'),\n",
      "   ('بار', 'N_SING'),\n",
      "   ('ویزیت', 'N_SING'),\n",
      "   ('تخصصی', 'ADJ'),\n",
      "   ('و', 'CON'),\n",
      "   ('فوق', 'ADJ'),\n",
      "   ('تخصصی', 'ADJ'),\n",
      "   ('با', 'P'),\n",
      "   ('دریافت', 'N_SING'),\n",
      "   ('بهای', 'N_SING'),\n",
      "   ('بسیار', 'ADV'),\n",
      "   ('اندک', 'ADJ'),\n",
      "   ('حدود', 'N_PL'),\n",
      "   ('3', 'NUM'),\n",
      "   ('هزار', 'NUM'),\n",
      "   ('تومانی', 'N_SING'),\n",
      "   ('برای', 'P'),\n",
      "   ('مردم', 'N_SING'),\n",
      "   ('طبقات', 'N_PL'),\n",
      "   ('محروم', 'ADJ'),\n",
      "   ('و', 'CON'),\n",
      "   ('متوسط', 'N_SING'),\n",
      "   ('انجام', 'N_SING'),\n",
      "   ('شد', 'V_PA'),\n",
      "   ('.', '.'),\n",
      "   ('وی', 'PRO'),\n",
      "   ('به', 'P'),\n",
      "   ('بیان', 'N_SING'),\n",
      "   ('مهمترین', 'ADJ_SUP'),\n",
      "   ('مشکلات', 'N_PL'),\n",
      "   ('پیش', 'P'),\n",
      "   ('روی', 'N_SING'),\n",
      "   ('طرح', 'N_SING'),\n",
      "   ('تحول', 'N_SING'),\n",
      "   ('سلامت', 'N_SING'),\n",
      "   ('پرداخت', 'V_PA'),\n",
      "   ('و', 'CON'),\n",
      "   ('گفت', 'V_PA'),\n",
      "   (':', 'DELM'),\n",
      "   ('مهمترین', 'ADJ_SUP'),\n",
      "   ('معضل', 'N_SING'),\n",
      "   ('این', 'DET'),\n",
      "   ('طرح', 'N_SING'),\n",
      "   ('،', 'DELM'),\n",
      "   ('عدم', 'N_SING'),\n",
      "   ('پایداری', 'N_SING'),\n",
      "   ('منابع', 'N_PL'),\n",
      "   ('است', 'V_PRS'),\n",
      "   ('و', 'CON'),\n",
      "   ('اعتبارات', 'N_PL'),\n",
      "   ('وزارت', 'N_SING'),\n",
      "   ('بهداشت', 'N_SING'),\n",
      "   ('در', 'P'),\n",
      "   ('سه', 'NUM'),\n",
      "   ('سال', 'N_SING'),\n",
      "   ('اخیر', 'ADJ'),\n",
      "   ('به\\u200cطور', 'P'),\n",
      "   ('کامل', 'ADJ'),\n",
      "   ('محقق', 'N_SING'),\n",
      "   ('نشد', 'V_PA'),\n",
      "   ('.', '.'),\n",
      "   ('آقاجانی', 'N_SING'),\n",
      "   ('تصریح', 'N_SING'),\n",
      "   ('کرد', 'V_PA'),\n",
      "   (':', 'DELM'),\n",
      "   ('در', 'P'),\n",
      "   ('سال', 'N_SING'),\n",
      "   ('95', 'ADJ'),\n",
      "   ('معادل', 'ADJ'),\n",
      "   ('یک', 'NUM'),\n",
      "   ('سوم', 'ADJ'),\n",
      "   ('بودجه', 'N_SING'),\n",
      "   ('سال', 'N_SING'),\n",
      "   ('93', 'ADJ'),\n",
      "   ('،', 'DELM'),\n",
      "   ('به', 'P'),\n",
      "   ('وزارت', 'N_SING'),\n",
      "   ('بهداشت', 'N_SING'),\n",
      "   ('بودجه', 'N_SING'),\n",
      "   ('تخصیص', 'N_SING'),\n",
      "   ('یافت', 'V_PA'),\n",
      "   ('اما', 'CON'),\n",
      "   ('خدمات', 'N_PL'),\n",
      "   ('حوزه', 'N_SING'),\n",
      "   ('سلامت', 'N_SING'),\n",
      "   ('همچنان', 'ADV'),\n",
      "   ('با', 'P'),\n",
      "   ('تلاش\\u200cها', 'N_PL'),\n",
      "   ('و', 'CON'),\n",
      "   ('زحمات', 'N_PL'),\n",
      "   ('جامعه', 'N_SING'),\n",
      "   ('پزشکی', 'N_SING'),\n",
      "   ('،', 'DELM'),\n",
      "   ('پرستاری', 'N_SING'),\n",
      "   ('و', 'CON'),\n",
      "   ('کادر', 'N_SING'),\n",
      "   ('بهداشتی', 'ADJ'),\n",
      "   ('و', 'CON'),\n",
      "   ('درمانی', 'ADJ'),\n",
      "   ('کشور', 'N_SING'),\n",
      "   ('،', 'DELM'),\n",
      "   ('بدون', 'P'),\n",
      "   ('هیچ\\u200cگونه', 'N_SING'),\n",
      "   ('کاستی', 'N_SING'),\n",
      "   ('به', 'P'),\n",
      "   ('مردم', 'N_SING'),\n",
      "   ('ارائه', 'N_SING'),\n",
      "   ('می\\u200cشود', 'V_PRS'),\n",
      "   ('.', '.'),\n",
      "   ('معاون', 'N_SING'),\n",
      "   ('درمان', 'N_SING'),\n",
      "   ('وزارت', 'N_SING'),\n",
      "   ('بهداشت', 'N_SING'),\n",
      "   ('تاکید', 'N_SING'),\n",
      "   ('کرد', 'V_PA'),\n",
      "   (':', 'DELM'),\n",
      "   ('برای', 'P'),\n",
      "   ('جبران', 'N_SING'),\n",
      "   ('کاهش', 'N_SING'),\n",
      "   ('بودجه', 'N_SING'),\n",
      "   ('وزارت', 'N_SING'),\n",
      "   ('بهداشت', 'N_SING'),\n",
      "   ('در', 'P'),\n",
      "   ('سال', 'N_SING'),\n",
      "   ('سوم', 'ADJ'),\n",
      "   ('اجرای', 'N_SING'),\n",
      "   ('طرح', 'N_SING'),\n",
      "   ('تحول', 'N_SING'),\n",
      "   ('سلامت', 'N_SING'),\n",
      "   ('نسبت', 'P'),\n",
      "   ('به', 'P'),\n",
      "   ('سال', 'N_SING'),\n",
      "   ('اول', 'ADJ'),\n",
      "   ('،', 'DELM'),\n",
      "   ('در', 'P'),\n",
      "   ('هزینه\\u200cهای', 'N_PL'),\n",
      "   ('به\\u200cطور', 'N_SING'),\n",
      "   ('جدی', 'ADJ'),\n",
      "   ('صرفه\\u200cجویی', 'N_SING'),\n",
      "   ('کردیم', 'V_PA'),\n",
      "   ('.', '.'),\n",
      "   ('اما', 'CON'),\n",
      "   ('سال', 'N_SING'),\n",
      "   ('گذشته', 'ADJ'),\n",
      "   ('از', 'P'),\n",
      "   ('محل', 'N_SING'),\n",
      "   ('هدفمندی', 'N_SING'),\n",
      "   ('یارانه\\u200cها', 'N_PL'),\n",
      "   ('نیز', 'CON'),\n",
      "   ('اعتباری', 'N_SING'),\n",
      "   ('دریافت', 'N_SING'),\n",
      "   ('نکردیم', 'V_PA'),\n",
      "   ('.', '.'),\n",
      "   ('آقاجانی', 'N_SING'),\n",
      "   ('در', 'P'),\n",
      "   ('خصوص', 'N_SING'),\n",
      "   ('وضعیت', 'N_SING'),\n",
      "   ('مطالبات', 'N_PL'),\n",
      "   ('وزارت', 'N_SING'),\n",
      "   ('بهداشت', 'N_SING'),\n",
      "   ('از', 'P'),\n",
      "   ('بیمه\\u200cها', 'N_PL'),\n",
      "   ('،', 'DELM'),\n",
      "   ('یادآور', 'ADJ'),\n",
      "   ('شد', 'V_PA'),\n",
      "   (':', 'DELM'),\n",
      "   ('بیمارستانهای', 'N_PL'),\n",
      "   ('وزارت', 'N_SING'),\n",
      "   ('بهداشت', 'N_SING'),\n",
      "   ('هنوز', 'ADV'),\n",
      "   ('مطالبات', 'N_PL'),\n",
      "   ('7', 'NUM'),\n",
      "   ('ماه', 'N_SING'),\n",
      "   ('از', 'P'),\n",
      "   ('سال', 'N_SING'),\n",
      "   ('گذشته', 'ADJ'),\n",
      "   ('را', 'CLITIC'),\n",
      "   ('از', 'P'),\n",
      "   ('بیمه\\u200cها', 'N_PL'),\n",
      "   ('دریافت', 'N_SING'),\n",
      "   ('نکرده\\u200cاند', 'V_PP'),\n",
      "   ('و', 'CON'),\n",
      "   ('حدود', 'N_PL'),\n",
      "   ('9', 'NUM'),\n",
      "   ('هزار', 'NUM'),\n",
      "   ('و', 'CON'),\n",
      "   ('500', 'NUM'),\n",
      "   ('میلیارد', 'NUM'),\n",
      "   ('تومان', 'N_SING'),\n",
      "   ('اسناد', 'N_PL'),\n",
      "   ('ارسالی', 'ADJ'),\n",
      "   ('به', 'P'),\n",
      "   ('بیمه\\u200cها', 'N_PL'),\n",
      "   ('دارند', 'V_PRS'),\n",
      "   ('.', '.'),\n",
      "   ('وی', 'PRO'),\n",
      "   ('به', 'P'),\n",
      "   ('وجود', 'N_SING'),\n",
      "   ('سامانه', 'N_SING'),\n",
      "   ('مرکزی', 'ADJ'),\n",
      "   ('خدمات', 'N_PL'),\n",
      "   ('بستری', 'ADJ'),\n",
      "   ('در', 'P'),\n",
      "   ('وزارت', 'N_SING'),\n",
      "   ('بهداشت', 'N_SING'),\n",
      "   ('اشاره', 'N_SING'),\n",
      "   ('کرد', 'V_PA'),\n",
      "   ('و', 'CON'),\n",
      "   ('افزود', 'V_PA'),\n",
      "   (':', 'DELM'),\n",
      "   ('بر', 'P'),\n",
      "   ('اساس', 'N_SING'),\n",
      "   ('اطلاعات', 'N_PL'),\n",
      "   ('این', 'DET'),\n",
      "   ('سامانه', 'N_SING'),\n",
      "   ('،', 'DELM'),\n",
      "   ('رشد', 'N_SING'),\n",
      "   ('خدمات', 'N_PL'),\n",
      "   ('بستری', 'ADJ'),\n",
      "   ('پس', 'ADV_TIME'),\n",
      "   ('از', 'P'),\n",
      "   ('طرح', 'N_SING'),\n",
      "   ('تحول', 'N_SING'),\n",
      "   ('سلامت', 'N_SING'),\n",
      "   ('،', 'DELM'),\n",
      "   ('فقط', 'ADV'),\n",
      "   ('5', 'NUM'),\n",
      "   ('درصد', 'N_SING'),\n",
      "   ('است', 'V_PRS'),\n",
      "   ('در', 'P'),\n",
      "   ('حالی', 'N_SING'),\n",
      "   ('که', 'CON'),\n",
      "   ('شاهد', 'N_SING'),\n",
      "   ('رشد', 'N_SING'),\n",
      "   ('11', 'ADJ'),\n",
      "   ('درصدی', 'N_SING'),\n",
      "   ('بیمه', 'N_SING'),\n",
      "   ('شدگان\\u200cبودیم', 'V_PA'),\n",
      "   ('بنابراین', 'CON'),\n",
      "   ('تقاضای', 'N_SING'),\n",
      "   ('القایی', 'N_SING'),\n",
      "   ('ایجاد\\u200cنشده\\u200cاما', 'PRO'),\n",
      "   ('در', 'P'),\n",
      "   ('حوزه', 'N_SING'),\n",
      "   ('خدمات', 'N_PL'),\n",
      "   ('سرپایی', 'ADJ'),\n",
      "   ('ممکن', 'ADJ'),\n",
      "   ('است', 'V_PRS'),\n",
      "   ('تقاضای', 'N_SING'),\n",
      "   ('القای', 'N_SING'),\n",
      "   ('وجود', 'N_SING'),\n",
      "   ('داشته', 'V_PP'),\n",
      "   ('باشد', 'V_SUB'),\n",
      "   ('چون', 'CON'),\n",
      "   ('دفترچه', 'N_SING'),\n",
      "   ('سفیدی', 'N_SING'),\n",
      "   ('را', 'CLITIC'),\n",
      "   ('در', 'P'),\n",
      "   ('اختیار', 'N_SING'),\n",
      "   ('مردم', 'N_SING'),\n",
      "   ('قرار', 'N_SING'),\n",
      "   ('می\\u200cدهیم', 'V_PRS'),\n",
      "   ('که', 'CON'),\n",
      "   ('ممکن', 'ADJ'),\n",
      "   ('است', 'V_PRS'),\n",
      "   ('هر', 'DET'),\n",
      "   ('روز', 'N_SING'),\n",
      "   ('به', 'P'),\n",
      "   ('پرشکان', 'N_PL'),\n",
      "   ('مختلف', 'ADJ'),\n",
      "   ('مراجعه', 'N_SING'),\n",
      "   ('کنند', 'V_SUB'),\n",
      "   ('و', 'CON'),\n",
      "   ('چندین', 'N_SING'),\n",
      "   ('خدمت', 'N_SING'),\n",
      "   ('پزشکی', 'N_SING'),\n",
      "   ('را', 'CLITIC'),\n",
      "   ('دریافت', 'N_SING'),\n",
      "   ('کنند', 'V_SUB'),\n",
      "   ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "pprinter.pprint(pos_tagged_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p></p>\n",
    "<br />\n",
    "<div id=\"sec_chunker\" style=\"direction:rtl;line-height:300%;\">\n",
    " <font face=\"B Nazanin\" size=6>\n",
    "  <font face=\"B Titr\" color=black size=5>\n",
    "             بخش‌ساز(Chunker)\n",
    "  </font>\n",
    "  <p></p>\n",
    "  <hr>\n",
    "در ابزار Parsivar، کلاس FindChunks فرایند بخش‌سازی(Chunking) را انجام می‌دهد. این فرایند در این ابزار، مبتنی بر قاعده(Rule-based) بوده و کلاس FindChunks از کلاس RegexpParser که در ماژول chunk ابزار NLTK تعبیه شده ارث‌بری می‌کند. دو متد chunk_sentence و convert_nestedtree2rawstring نیز به ترتیب برای بخش‌ سازی و تبدیل درخت تجزیه بخش‌ها به رشته استفاده می‌شود.\n",
    " </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "INXHrj5wEaXn"
   },
   "outputs": [],
   "source": [
    "chunker = FindChunks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "xNGC26fCEaXo"
   },
   "outputs": [],
   "source": [
    "chunks = chunker.chunk_sentence(pos_tagged_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LNpZUbvSEaXo",
    "outputId": "2089c6bc-dc80-45a9-f1be-0b381db4ddda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('[به گزارش خبرنگار حوزه بهداشت NPP] و [درمان گروه علمی پزشکی باشگاه خبرنگاران '\n",
      " 'جوان NP] ؛ [محمد آقاجانی روز دوشنبه NP] [در نشست مشترک NPP] و هم [اندیشی '\n",
      " 'اعضای کمیسیون برنامه NP] ، [بودجه NP] و [محاسبات مجلس NP] و [شورای معاونین '\n",
      " 'وزارت بهداشت NP] ، [اظهار داشت VP] : [در PP] بیش [از 600 کلینیک ویژه NPP] '\n",
      " '[در سطح کشور NPP] [از ابتدای طرح تحول سلامت NPP] [تا پایان سال گذشته NPP] ، '\n",
      " '[110 میلیون بار ویزیت تخصصی NP] و فوق تخصصی [با دریافت بهای NPP] بسیار [اندک '\n",
      " 'حدود 3 هزار تومانی NP] [برای مردم طبقات محروم NPP] و [متوسط NP] [انجام شد '\n",
      " 'VP] . وی [به بیان مهمترین مشکلات NPP] [پیش روی طرح تحول NPP] [سلامت پرداخت '\n",
      " 'VP] و [گفت VP] : [مهمترین معضل این طرح DDNP] ، [عدم پایداری منابع NP] [است '\n",
      " 'VP] و [اعتبارات وزارت بهداشت NP] [در سه سال اخیر NPP] [به\\u200cطور PP] کامل '\n",
      " '[محقق نشد VP] . [آقاجانی NP] [تصریح کرد VP] : [در سال 95 معادل یک سوم بودجه '\n",
      " 'سال 93 NPP] ، [به وزارت بهداشت بودجه NPP] [تخصیص یافت VP] اما [خدمات حوزه '\n",
      " 'سلامت NP] همچنان [با تلاش\\u200cها NPP] و [زحمات جامعه پزشکی NP] ، [پرستاری '\n",
      " 'NP] و [کادر بهداشتی NP] و [درمانی کشور NP] ، [بدون هیچ\\u200cگونه کاستی NPP] '\n",
      " '[به مردم NPP] [ارائه می\\u200cشود VP] . [معاون درمان وزارت بهداشت NP] [تاکید '\n",
      " 'کرد VP] : [برای جبران کاهش بودجه وزارت بهداشت NPP] [در سال سوم اجرای طرح '\n",
      " 'تحول سلامت NPP] [نسبت به سال اول NPP] ، [در هزینه\\u200cهای به\\u200cطور جدی '\n",
      " 'صرفه\\u200cجویی NPP] [کردیم VP] . اما [سال گذشته NP] [از محل هدفمندی '\n",
      " 'یارانه\\u200cها NPP] نیز [اعتباری NP] [دریافت نکردیم VP] . [آقاجانی NP] [در '\n",
      " 'خصوص وضعیت مطالبات وزارت بهداشت NPP] [از بیمه\\u200cها NPP] ، یادآور [شد VP] '\n",
      " ': [بیمارستانهای وزارت بهداشت NP] هنوز [مطالبات 7 ماه NP] [از سال گذشته NPP] '\n",
      " 'را [از بیمه\\u200cها NPP] [دریافت نکرده\\u200cاند VP] و [حدود 9 هزار NP] و '\n",
      " '[500 میلیارد تومان اسناد ارسالی NP] [به بیمه\\u200cها NPP] [دارند VP] . وی '\n",
      " '[به وجود سامانه مرکزی خدمات بستری NPP] [در وزارت بهداشت NPP] [اشاره کرد VP] '\n",
      " 'و [افزود VP] : [بر PP] [اساس اطلاعات این سامانه DDNP] ، [رشد خدمات بستری NP] '\n",
      " 'پس [از طرح تحول سلامت NPP] ، فقط [5 NP] [درصد است VP] [در حالی NPP] که [شاهد '\n",
      " 'رشد 11 درصدی NP] [بیمه شدگان\\u200cبودیم VP] بنابراین [تقاضای القایی '\n",
      " 'ایجاد\\u200cنشده\\u200cاما NP] [در حوزه خدمات سرپایی NPP] ممکن [است VP] '\n",
      " '[تقاضای القای NP] [وجود داشته باشد VP] چون [دفترچه سفیدی NP] را [در اختیار '\n",
      " 'مردم NPP] [قرار می\\u200cدهیم VP] که ممکن [است VP] [هر روز DNP] [به پرشکان '\n",
      " 'مختلف NPP] [مراجعه کنند VP] و [چندین خدمت پزشکی NP] را [دریافت کنند VP] .')\n"
     ]
    }
   ],
   "source": [
    "pprinter.pprint(chunker.convert_nestedtree2rawstring(chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p></p>\n",
    "<br />\n",
    "<div id=\"sec_dependency_parser\" style=\"direction:rtl;line-height:300%;\">\n",
    " <font face=\"B Nazanin\" size=6>\n",
    "  <font face=\"B Titr\" color=black size=5>\n",
    "             تجزیه‌گر وابستگی(Dependency Parser)\n",
    "  </font>\n",
    "  <p></p>\n",
    "  <hr>\n",
    "در ابزار Parsivar، کلاس DependencyParser وظیفه تجزیه و تحلیل نحوی و رسم گراف وابستگی را بر عهده دارد. به کمک متد parse_sents می‌توان تجزیه را بر روی جملات انجام داد. همچنین در سازنده این کلاس نمونه‌ای از کلاس MyMaltParser که از ماژول parse ابزار NLTK ارث‌بری می‌کند، ساخته می‌شود. بنابراین تجزیه‌گر وابستگی در ابزار Parsivar به طور غیرمستقیم از تجزیه‌گر ابزار NLTK استفاده می‌کند.\n",
    " </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "QDGPfNczEaXp"
   },
   "outputs": [],
   "source": [
    "parser = DependencyParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "0rBKNQLwEaXp"
   },
   "outputs": [],
   "source": [
    "lorem_ipsum = 'لورم ایپسوم متن ساختگی با تولید سادگی نامفهوم از صنعت چاپ، و با استفاده از طراحان گرافیک است'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "j54yby_cEaXq"
   },
   "outputs": [],
   "source": [
    "parsed_sents = parser.parse_sents(tokenizer.tokenize_sentences(lorem_ipsum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wNVGvKLTggQb",
    "outputId": "8a528bd0-ebb9-4ef2-daf5-4258ab07fcc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(است\n",
      "  (لورم (ایپسوم (متن ساختگی)))\n",
      "  (با (تولید (سادگی نامفهوم)))\n",
      "  (گرافیک (از (صنعت چاپ،) (و (با (استفاده (از طراحان)))))))\n"
     ]
    }
   ],
   "source": [
    "for depgraph in parsed_sents:\n",
    "    print(depgraph.tree())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p></p>\n",
    "<br />\n",
    "<div id=\"sec_spell_check\" style=\"direction:rtl;line-height:300%;\">\n",
    " <font face=\"B Nazanin\" size=6>\n",
    "  <font face=\"B Titr\" color=black size=5>\n",
    "             بررسی املا(Spell Check)\n",
    "  </font>\n",
    "  <p></p>\n",
    "  <hr>\n",
    "     بررسی املا از جمله قابلیت‌های جالب و ارزنده در پردازش متن می‌باشد. در ابزار Parsivar این قابلیت به کمک کلاس SpellCheck محقق می‌شود.\n",
    " </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"B Nazanin\" size=6>\n",
    "\t\t<div>\n",
    "\t\t\t<ul style=\"margin-right: 0;\">\n",
    "\t\t\t\t<li>\n",
    "                     spell_corrector\n",
    "                    <ul style=\"margin-right: 0;\">\n",
    "                        <li>\n",
    "                        بررسی و اصلاح املای جمله\n",
    "                        </li>\n",
    "                    </ul>\n",
    "                 </li>\n",
    "                 <li>\n",
    "                     select_correct_spell\n",
    "                     <ul style=\"margin-right: 0;\">\n",
    "                        <li>\n",
    "                            انتخاب بهترین املا برای هر کلمه\n",
    "                        </li>\n",
    "                    </ul>\n",
    "                 </li>    \n",
    "                <li>\n",
    "                    is_ingroup_substitution\n",
    "                    <ul style=\"margin-right: 0;\">\n",
    "                        <li>\n",
    "                            بررسی هم‌گروه بودن کلمات در فرایند تعویض کاراکترها\n",
    "                        </li>\n",
    "                    </ul>\n",
    "                </li>\n",
    "                <li>\n",
    "                    select_n_best\n",
    "                    <ul style=\"margin-right: 0;\">\n",
    "                        <li>\n",
    "                            انتخاب n بهترین کلمه(املا) کاندید\n",
    "                        </li>\n",
    "                    </ul>\n",
    "                </li>\n",
    "                <li>\n",
    "                    get_possible_words\n",
    "                    <ul style=\"margin-right: 0;\">\n",
    "                        <li>\n",
    "                            به دست آوردن همه کلمات(املاها) ممکن\n",
    "                        </li>\n",
    "                    </ul>\n",
    "                </li>\n",
    "                <li>\n",
    "                    isword\n",
    "                    <ul style=\"margin-right: 0;\">\n",
    "                        <li>\n",
    "                            آیا یک کلمه(املا) قابل قبول است؟\n",
    "                        </li>\n",
    "                    </ul>\n",
    "                </li>\n",
    "                <li>\n",
    "                    get_word_probability\n",
    "                    <ul style=\"margin-right: 0;\">\n",
    "                        <li>\n",
    "                            محاسبه احتمال کلمه(املا یا unigram)\n",
    "                        </li>\n",
    "                    </ul>\n",
    "                </li>\n",
    "                <li>\n",
    "                    bigram_markov_factor\n",
    "                    <ul style=\"margin-right: 0;\">\n",
    "                        <li>\n",
    "                            محاسبه ضریب مارکوف bigram\n",
    "                        </li>\n",
    "                    </ul>\n",
    "                </li>\n",
    "                <li>\n",
    "                    build_similar_words\n",
    "                    <ul style=\"margin-right: 0;\">\n",
    "                        <li>\n",
    "                            ساختن کلمات مشابه بر اساس عملگر(Merge یا Split یا Spell)\n",
    "                        </li>\n",
    "                    </ul>\n",
    "                </li>\n",
    "                <li>\n",
    "                    transposition\n",
    "                    <ul style=\"margin-right: 0;\">\n",
    "                        <li>\n",
    "                            جابجایی هر کاراکتر با کاراکتر بعدی\n",
    "                        </li>\n",
    "                    </ul>\n",
    "                </li>\n",
    "                <li>\n",
    "                    substitution\n",
    "                    <ul style=\"margin-right: 0;\">\n",
    "                        <li>\n",
    "                            جایگزینی هر کاراکتر با تمامی حروف الفبا\n",
    "                        </li>\n",
    "                    </ul>\n",
    "                </li>\n",
    "                <li>\n",
    "                    insertion\n",
    "                    <ul style=\"margin-right: 0;\">\n",
    "                        <li>\n",
    "                            اضافه‌کردن حروف الفبا به هر کاراکتر\n",
    "                        </li>\n",
    "                    </ul>\n",
    "                </li>\n",
    "                <li>\n",
    "                    splitting\n",
    "                    <ul style=\"margin-right: 0;\">\n",
    "                        <li>\n",
    "                            شکستن کلمه به دو قسمت\n",
    "                        </li>\n",
    "                    </ul>\n",
    "                </li>\n",
    "                <li>\n",
    "                    deletion\n",
    "                    <ul style=\"margin-right: 0;\">\n",
    "                        <li>\n",
    "                            حذف هر یک از حروف کلمه\n",
    "                        </li>\n",
    "                    </ul>\n",
    "                </li>\n",
    "\t\t\t</ul>\n",
    "\t\t</div>\n",
    "\t</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note \n",
    "\n",
    "**To use the spell checker module, download it's resources from [here](https://www.dropbox.com/s/tlyvnzv1ha9y1kl/spell.zip?dl=0) and after extraction, copy the `spell/` directory to `parsivar/resource`.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "N5e0OdffEaXs"
   },
   "outputs": [],
   "source": [
    "spell_checker = SpellCheck()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: parsivar\r\n",
      "Version: 0.2.3\r\n",
      "Summary: Python library for preprocessing Persian text.\r\n",
      "Home-page: UNKNOWN\r\n",
      "Author: ICT\r\n",
      "Author-email: \r\n",
      "License: UNKNOWN\r\n",
      "Location: /home/mohsen-mahmoudzadeh/.local/lib/python3.8/site-packages\r\n",
      "Requires: nltk\r\n",
      "Required-by: \r\n"
     ]
    }
   ],
   "source": [
    "# Use the following command to find the location of Parsivar module.\n",
    "!pip show parsivar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "Nrxbv4RWEaXs"
   },
   "outputs": [],
   "source": [
    "misspelled_input = 'من بصیار به ضبان فارصی مصلت حصطم'\n",
    "spell_checked_text = spell_checker.spell_corrector(misspelled_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "Tp73_0KcEaXs",
    "outputId": "659503c5-ad73-4b03-a389-87fe8ec15c14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'من بسیار به زبان فارسی مثلت حصطم'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spell_checked_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kKPYLi-qggQk"
   },
   "source": [
    "<p></p>\n",
    "<br />\n",
    "<div id=\"sec_resources\" style=\"direction:rtl;line-height:300%;\">\n",
    " <font face=\"B Nazanin\" size=6>\n",
    "  <font face=\"B Titr\" color=black size=6>\n",
    "منابع\n",
    "        </font>\n",
    "  <p></p>\n",
    " </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fASjiW9qggQk"
   },
   "source": [
    "1. https://github.com/ICTRC/Parsivar\n",
    "2. https://github.com/mohamad-dehghani/tutorial/blob/master/Parsivar.ipynb\n",
    "3. https://www.nltk.org/"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Parsivar.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
